{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Your First Agent\n",
    "\n",
    "In this notebook, you'll learn how to build and customize Victor agents for different use cases.\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you'll be able to:\n",
    "- Create agents with different configurations\n",
    "- Use tools to extend agent capabilities\n",
    "- Stream responses in real-time\n",
    "- Maintain multi-turn conversations\n",
    "- Use verticals for domain-specific tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Agent Creation\n",
    "\n",
    "The simplest way to create an agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from victor import Agent\n",
    "\n",
    "# Create a basic agent\n",
    "agent = Agent.create()\n",
    "\n",
    "# Use it\n",
    "result = await agent.run(\"Explain async/await in Python in simple terms.\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Selecting a Provider\n",
    "\n",
    "Victor supports multiple LLM providers. Let's try different ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI GPT-4\n",
    "gpt4 = Agent.create(\n",
    "    provider=\"openai\",\n",
    "    model=\"gpt-4\"\n",
    ")\n",
    "\n",
    "# Anthropic Claude\n",
    "claude = Agent.create(\n",
    "    provider=\"anthropic\",\n",
    "    model=\"claude-3-opus-20240229\"\n",
    ")\n",
    "\n",
    "# Local Ollama (no API key needed!)\n",
    "# ollama = Agent.create(\n",
    "#     provider=\"ollama\",\n",
    "#     model=\"llama2\"\n",
    "# )\n",
    "\n",
    "print(\"Agents created with different providers!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding Tools\n",
    "\n",
    "Tools give agents the ability to perform actions. Let's create an agent with filesystem tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent with filesystem tools\n",
    "file_agent = Agent.create(\n",
    "    tools=[\"read\", \"write\", \"ls\", \"grep\"]\n",
    ")\n",
    "\n",
    "# Ask it to analyze files\n",
    "result = await file_agent.run(\n",
    "    \"List all Python files in the current directory and count total lines of code.\"\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Tools\n",
    "\n",
    "| Category | Tools |\n",
    "|----------|-------|\n",
    "| Filesystem | `read`, `write`, `edit`, `ls`, `grep` |\n",
    "| Git | `git_status`, `git_commit`, `git_push` |\n",
    "| Web | `web_search`, `web_fetch` |\n",
    "| Execution | `shell`, `python` |\n",
    "| Docker | `docker_build`, `docker_run` |\n",
    "\n",
    "You can also use presets:\n",
    "- `tools=\"minimal\"` - No filesystem access\n",
    "- `tools=\"default\"` - Safe filesystem operations\n",
    "- `tools=\"full\"` - All available tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Streaming Responses\n",
    "\n",
    "For long responses, streaming provides real-time feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent for streaming\n",
    "agent = Agent.create()\n",
    "\n",
    "# Stream the response\n",
    "print(\"Agent is thinking...\\n\")\n",
    "\n",
    "async for event in agent.stream(\"Tell me a short story about AI:\"):\n",
    "    if event.type == \"content\":\n",
    "        print(event.content, end=\"\", flush=True)\n",
    "    elif event.type == \"thinking\":\n",
    "        print(\"\\n[Thinking...]\")\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-turn Conversations\n",
    "\n",
    "Agents maintain conversation context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent\n",
    "agent = Agent.create()\n",
    "\n",
    "# Multi-turn conversation\n",
    "print(\"=== Conversation ===\")\n",
    "\n",
    "response1 = await agent.chat(\"My name is Alice and I love Python.\")\n",
    "print(f\"You: My name is Alice and I love Python.\")\n",
    "print(f\"Agent: {response1.content}\\n\")\n",
    "\n",
    "response2 = await agent.chat(\"What's my name and what programming language do I love?\")\n",
    "print(f\"You: What's my name and what programming language do I love?\")\n",
    "print(f\"Agent: {response2.content}\\n\")\n",
    "\n",
    "print(\"The agent remembered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using Verticals\n",
    "\n",
    "Verticals are pre-configured for specific domains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coding vertical\n",
    "coding_agent = Agent.create(\n",
    "    vertical=\"coding\",\n",
    "    tools=[\"read\", \"write\", \"edit\", \"grep\"]\n",
    ")\n",
    "\n",
    "result = await coding_agent.run(\n",
    "    \"Review this code and suggest improvements: \\n\\n\"\n",
    "    \"def add(a, b):\\n\"\n",
    "    \"    return a + b\\n\"\n",
    ")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available Verticals\n",
    "\n",
    "- `coding` - Code generation, review, debugging\n",
    "- `devops` - Infrastructure, CI/CD, containers\n",
    "- `research` - Research and information gathering\n",
    "- `dataanalysis` - Data exploration and analysis\n",
    "- `rag` - Retrieval-augmented generation\n",
    "- `security` - Security analysis and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Custom System Prompts\n",
    "\n",
    "Override the default behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom personality\n",
    "pirate_agent = Agent.create(\n",
    "    system_prompt=\"You are a helpful assistant who speaks like a pirate. Use nautical terminology and pirate slang.\"\n",
    ")\n",
    "\n",
    "result = await pirate_agent.run(\"Hello, how are you?\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Build Your Agent\n",
    "\n",
    "Create an agent that:\n",
    "1. Uses a specific provider (try OpenAI or Anthropic)\n",
    "2. Has access to at least 2 tools\n",
    "3. Has a custom system prompt\n",
    "4. Asks it a question relevant to its configuration\n",
    "\n",
    "ðŸ’¡ Use the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your custom agent here\n",
    "\n",
    "\n",
    "# Test it\n",
    "# result = await your_agent.run(\"Your question\")\n",
    "# print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you learned:\n",
    "- âœ… Creating agents with different providers\n",
    "- âœ… Adding tools to extend capabilities\n",
    "- âœ… Streaming responses for real-time feedback\n",
    "- âœ… Multi-turn conversations\n",
    "- âœ… Using verticals for domain-specific tasks\n",
    "- âœ… Custom system prompts\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Continue to [02_workflows.ipynb](./02_workflows.ipynb) to learn about creating multi-step workflows!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
