// Copyright 2025 Vijaykumar Singh <singhvjd@gmail.com>
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! High-performance document chunking for RAG.
//!
//! This module provides fast text chunking with:
//! - Sentence-boundary aware splitting
//! - Configurable chunk size and overlap
//! - 10-50x faster than Python regex-based chunking

use pyo3::prelude::*;

/// Sentence boundary patterns (optimized for English)
const SENTENCE_ENDINGS: &[char] = &['.', '!', '?'];
const ABBREVIATIONS: &[&str] = &[
    "Mr.", "Mrs.", "Ms.", "Dr.", "Prof.", "Sr.", "Jr.", "vs.", "etc.", "i.e.", "e.g.", "cf.",
    "viz.", "Inc.", "Corp.", "Ltd.", "Co.", "No.", "Vol.", "Jan.", "Feb.", "Mar.", "Apr.", "Jun.",
    "Jul.", "Aug.", "Sep.", "Oct.", "Nov.", "Dec.",
];

/// Check if position is a valid sentence boundary
fn is_sentence_boundary(text: &str, pos: usize) -> bool {
    if pos >= text.len() {
        return false;
    }

    let char_at = text.chars().nth(pos).unwrap_or(' ');
    if !SENTENCE_ENDINGS.contains(&char_at) {
        return false;
    }

    // Check it's not an abbreviation
    let start = pos.saturating_sub(10);
    let prefix = &text[start..=pos];

    for abbr in ABBREVIATIONS {
        if prefix.ends_with(abbr) {
            return false;
        }
    }

    // Must be followed by space/newline and capital letter (or end)
    if pos + 1 >= text.len() {
        return true;
    }

    let next_chars: String = text[pos + 1..].chars().take(3).collect();
    if next_chars.starts_with(' ') || next_chars.starts_with('\n') {
        // Check for capital letter after whitespace
        for c in next_chars.chars().skip(1) {
            if c.is_alphabetic() {
                return c.is_uppercase();
            }
            if !c.is_whitespace() {
                return true; // Non-alpha, non-space (like quotes)
            }
        }
        return true;
    }

    false
}

/// Find all sentence boundaries in text
fn find_sentence_boundaries(text: &str) -> Vec<usize> {
    let mut boundaries = vec![0]; // Start of text

    for (i, c) in text.char_indices() {
        if SENTENCE_ENDINGS.contains(&c) && is_sentence_boundary(text, i) {
            boundaries.push(i + 1);
        }
    }

    if !boundaries.contains(&text.len()) {
        boundaries.push(text.len());
    }

    boundaries
}

/// Chunk text by sentences with configurable size and overlap
#[pyfunction]
#[pyo3(signature = (text, chunk_size=1344, overlap=128))]
pub fn chunk_by_sentences(text: &str, chunk_size: usize, overlap: usize) -> Vec<String> {
    let boundaries = find_sentence_boundaries(text);
    let mut chunks = Vec::new();

    if boundaries.len() <= 1 {
        // No sentence boundaries, fall back to character chunking
        return chunk_by_chars(text, chunk_size, overlap);
    }

    let mut chunk_start = 0;
    let mut current_end = 0;

    for i in 1..boundaries.len() {
        let boundary = boundaries[i];
        let chunk_len = boundary - chunk_start;

        if chunk_len >= chunk_size {
            // Emit chunk up to previous boundary
            if current_end > chunk_start {
                let chunk = text[chunk_start..current_end].trim().to_string();
                if !chunk.is_empty() {
                    chunks.push(chunk);
                }
                // Move start back by overlap
                chunk_start = if current_end > overlap {
                    // Find sentence boundary in overlap region
                    let overlap_start = current_end.saturating_sub(overlap);
                    boundaries
                        .iter()
                        .find(|&&b| b >= overlap_start && b < current_end)
                        .copied()
                        .unwrap_or(overlap_start)
                } else {
                    0
                };
            }
        }
        current_end = boundary;
    }

    // Emit final chunk
    if current_end > chunk_start {
        let chunk = text[chunk_start..current_end].trim().to_string();
        if !chunk.is_empty() {
            chunks.push(chunk);
        }
    }

    chunks
}

/// Simple character-based chunking with overlap
#[pyfunction]
#[pyo3(signature = (text, chunk_size=1344, overlap=128))]
pub fn chunk_by_chars(text: &str, chunk_size: usize, overlap: usize) -> Vec<String> {
    let mut chunks = Vec::new();
    let chars: Vec<char> = text.chars().collect();
    let text_len = chars.len();

    if text_len == 0 {
        return chunks;
    }

    let mut start = 0;
    while start < text_len {
        let end = (start + chunk_size).min(text_len);
        let chunk: String = chars[start..end].iter().collect();
        let trimmed = chunk.trim().to_string();
        if !trimmed.is_empty() {
            chunks.push(trimmed);
        }

        if end >= text_len {
            break;
        }

        start = end.saturating_sub(overlap);
    }

    chunks
}

/// Chunk text by paragraph boundaries
#[pyfunction]
#[pyo3(signature = (text, chunk_size=1344, overlap=128))]
pub fn chunk_by_paragraphs(text: &str, chunk_size: usize, overlap: usize) -> Vec<String> {
    // Split on double newlines (paragraph boundaries)
    let paragraphs: Vec<&str> = text.split("\n\n").collect();
    let mut chunks = Vec::new();
    let mut current_chunk = String::new();

    for para in paragraphs {
        let para = para.trim();
        if para.is_empty() {
            continue;
        }

        let would_be_len = current_chunk.len() + para.len() + 2; // +2 for \n\n

        if would_be_len > chunk_size && !current_chunk.is_empty() {
            // Emit current chunk
            chunks.push(current_chunk.trim().to_string());

            // Start new chunk with overlap from previous
            let overlap_text = if current_chunk.len() > overlap {
                &current_chunk[current_chunk.len() - overlap..]
            } else {
                &current_chunk
            };
            current_chunk = overlap_text.to_string();
        }

        if !current_chunk.is_empty() {
            current_chunk.push_str("\n\n");
        }
        current_chunk.push_str(para);
    }

    // Emit final chunk
    if !current_chunk.is_empty() {
        chunks.push(current_chunk.trim().to_string());
    }

    chunks
}

/// Detect document type from file extension
#[pyfunction]
pub fn detect_doc_type(source: &str) -> String {
    let source_lower = source.to_lowercase();

    // Check file extension
    let extensions = [
        (".html", "html"),
        (".htm", "html"),
        (".xhtml", "html"),
        (".md", "markdown"),
        (".markdown", "markdown"),
        (".rst", "markdown"),
        (".py", "code"),
        (".js", "code"),
        (".ts", "code"),
        (".java", "code"),
        (".go", "code"),
        (".rs", "code"),
        (".c", "code"),
        (".cpp", "code"),
        (".json", "json"),
        (".yaml", "yaml"),
        (".yml", "yaml"),
        (".xml", "xml"),
        (".csv", "csv"),
        (".txt", "text"),
    ];

    for (ext, doc_type) in extensions {
        if source_lower.ends_with(ext) {
            return doc_type.to_string();
        }
    }

    // Default to text
    "text".to_string()
}

/// Count approximate tokens (words + punctuation)
#[pyfunction]
pub fn count_tokens_approx(text: &str) -> usize {
    // Approximate: 1 token â‰ˆ 4 characters for English
    // More accurate: count words + punctuation
    let mut tokens = 0;
    let mut in_word = false;

    for c in text.chars() {
        if c.is_alphanumeric() {
            if !in_word {
                tokens += 1;
                in_word = true;
            }
        } else {
            in_word = false;
            if c.is_ascii_punctuation() {
                tokens += 1;
            }
        }
    }

    tokens
}

// =============================================================================
// LINE-AWARE CHUNKING (Protocol-compliant)
// =============================================================================

/// Count lines in text (newline count + 1).
///
/// # Arguments
/// * `text` - Text to count lines in
///
/// # Returns
/// Number of lines (1 for empty string with no newlines)
#[pyfunction]
pub fn count_lines(text: &str) -> usize {
    if text.is_empty() {
        return 0;
    }
    text.bytes().filter(|&b| b == b'\n').count() + 1
}

/// Find byte offsets of all line starts.
///
/// # Arguments
/// * `text` - Text to analyze
///
/// # Returns
/// List of byte offsets where lines start (always includes 0)
#[pyfunction]
pub fn find_line_boundaries(text: &str) -> Vec<usize> {
    if text.is_empty() {
        return Vec::new();
    }

    let mut boundaries = vec![0];
    for (i, b) in text.bytes().enumerate() {
        if b == b'\n' && i + 1 < text.len() {
            boundaries.push(i + 1);
        }
    }
    boundaries
}

/// Get line number for a character offset using binary search.
///
/// # Arguments
/// * `text` - Text
/// * `offset` - Character offset
///
/// # Returns
/// Line number (1-indexed)
#[pyfunction]
pub fn line_at_offset(text: &str, offset: usize) -> usize {
    if text.is_empty() || offset == 0 {
        return 1;
    }

    let offset = offset.min(text.len().saturating_sub(1));

    // Count newlines before offset
    text[..offset].bytes().filter(|&b| b == b'\n').count() + 1
}

/// Chunk information with line numbers and offsets.
#[pyclass]
#[derive(Clone)]
pub struct ChunkInfoRust {
    #[pyo3(get)]
    pub text: String,
    #[pyo3(get)]
    pub start_line: usize,
    #[pyo3(get)]
    pub end_line: usize,
    #[pyo3(get)]
    pub start_offset: usize,
    #[pyo3(get)]
    pub end_offset: usize,
    #[pyo3(get)]
    pub overlap_prev: usize,
    #[pyo3(get)]
    pub chunk_index: usize,
}

#[pymethods]
impl ChunkInfoRust {
    #[new]
    pub fn new(
        text: String,
        start_line: usize,
        end_line: usize,
        start_offset: usize,
        end_offset: usize,
        overlap_prev: usize,
        chunk_index: usize,
    ) -> Self {
        Self {
            text,
            start_line,
            end_line,
            start_offset,
            end_offset,
            overlap_prev,
            chunk_index,
        }
    }
}

/// Chunk text with overlap, respecting line boundaries.
///
/// Returns full chunk information including line numbers and offsets.
///
/// # Arguments
/// * `text` - Text to chunk
/// * `chunk_size` - Target chunk size in characters
/// * `overlap` - Overlap size in characters
///
/// # Returns
/// List of ChunkInfoRust objects with full metadata
#[pyfunction]
#[pyo3(signature = (text, chunk_size=1344, overlap=128))]
pub fn chunk_with_overlap(text: &str, chunk_size: usize, overlap: usize) -> PyResult<Vec<ChunkInfoRust>> {
    if text.is_empty() {
        return Ok(Vec::new());
    }

    if chunk_size == 0 {
        return Err(pyo3::exceptions::PyValueError::new_err(
            "chunk_size must be positive",
        ));
    }

    if overlap >= chunk_size {
        return Err(pyo3::exceptions::PyValueError::new_err(
            "overlap must be less than chunk_size",
        ));
    }

    // Pre-compute line boundaries for efficient line number lookup
    let line_starts = find_line_boundaries(text);

    let mut chunks = Vec::new();
    let mut pos = 0;
    let mut chunk_index = 0;
    let text_len = text.len();

    while pos < text_len {
        // Calculate chunk end
        let mut chunk_end = (pos + chunk_size).min(text_len);

        // If not at end, try to find a line boundary
        if chunk_end < text_len {
            // Look for a newline within the chunk
            if let Some(last_newline) = text[pos..chunk_end].rfind('\n') {
                let absolute_pos = pos + last_newline;
                if absolute_pos > pos {
                    chunk_end = absolute_pos + 1; // Include the newline
                }
            }
        }

        // Extract chunk text
        let chunk_text = text[pos..chunk_end].to_string();

        // Calculate line numbers using binary search
        let start_line = line_at_offset_cached(&line_starts, pos);
        let end_line = line_at_offset_cached(&line_starts, chunk_end.saturating_sub(1));

        // Calculate overlap with previous chunk
        let overlap_prev = if chunk_index > 0 && pos > 0 {
            overlap.min(pos)
        } else {
            0
        };

        chunks.push(ChunkInfoRust::new(
            chunk_text,
            start_line,
            end_line,
            pos,
            chunk_end,
            overlap_prev,
            chunk_index,
        ));

        // Move position forward, accounting for overlap
        let step = (chunk_size.saturating_sub(overlap)).max(1);
        pos += step;
        chunk_index += 1;

        // Adjust position to line boundary if we have overlap
        if pos < text_len && overlap > 0 {
            let overlap_start = pos.saturating_sub(overlap);
            if let Some(next_newline) = text[overlap_start..pos.min(text_len)].find('\n') {
                let absolute_pos = overlap_start + next_newline;
                if absolute_pos < pos {
                    pos = absolute_pos + 1;
                }
            }
        }
    }

    Ok(chunks)
}

/// Binary search for line number using pre-computed boundaries.
#[inline]
fn line_at_offset_cached(line_starts: &[usize], offset: usize) -> usize {
    if line_starts.is_empty() {
        return 1;
    }

    // Binary search for the line containing offset
    match line_starts.binary_search(&offset) {
        Ok(idx) => idx + 1, // Exact match, 1-indexed
        Err(idx) => idx,    // Insert position = line number (already 1-indexed due to 0 at start)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_chunk_by_sentences() {
        let text = "Hello world. This is a test. Another sentence here.";
        let chunks = chunk_by_sentences(text, 30, 10);
        assert!(!chunks.is_empty());
    }

    #[test]
    fn test_chunk_by_chars() {
        let text = "Hello world this is a test of chunking";
        let chunks = chunk_by_chars(text, 15, 5);
        assert!(chunks.len() >= 2);
    }

    #[test]
    fn test_detect_doc_type() {
        assert_eq!(detect_doc_type("file.py"), "code");
        assert_eq!(detect_doc_type("doc.md"), "markdown");
        assert_eq!(detect_doc_type("page.html"), "html");
        assert_eq!(detect_doc_type("data.json"), "json");
    }

    #[test]
    fn test_count_tokens() {
        let text = "Hello, world! This is a test.";
        let tokens = count_tokens_approx(text);
        assert!(tokens >= 6); // At least 6 words + punctuation
    }
}
