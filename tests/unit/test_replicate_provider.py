# Copyright 2025 Vijaykumar Singh
# SPDX-License-Identifier: Apache-2.0
"""Comprehensive unit tests for Replicate provider."""

import json
from unittest.mock import AsyncMock, MagicMock, patch

import httpx
import pytest

from victor.providers.replicate_provider import ReplicateProvider, REPLICATE_MODELS


class TestReplicateProviderInitialization:
    """Tests for ReplicateProvider initialization."""

    def test_initialization_with_api_key(self):
        """Test initialization with explicit API key."""
        provider = ReplicateProvider(api_key="r8_test_token_123")
        assert provider._api_key == "r8_test_token_123"
        assert provider.name == "replicate"

    def test_initialization_from_env_var(self):
        """Test API key loading from environment variable."""
        with patch.dict("os.environ", {"REPLICATE_API_TOKEN": "r8_env_token"}):
            provider = ReplicateProvider()
            assert provider._api_key == "r8_env_token"

    def test_initialization_from_keyring(self):
        """Test API key loading from keyring when env var not set."""
        with patch.dict("os.environ", {"REPLICATE_API_TOKEN": ""}, clear=False):
            with patch(
                "victor.config.api_keys.get_api_key",
                return_value="keyring-replicate-key",
            ):
                provider = ReplicateProvider()
                assert provider._api_key == "keyring-replicate-key"

    def test_initialization_warning_without_key(self, caplog):
        """Test warning is logged when no API key provided."""
        with patch.dict("os.environ", {"REPLICATE_API_TOKEN": ""}, clear=False):
            with patch(
                "victor.config.api_keys.get_api_key",
                return_value=None,
            ):
                provider = ReplicateProvider()
                assert provider._api_key == ""

    def test_default_timeout_is_high(self):
        """Test default timeout is high for cold starts."""
        provider = ReplicateProvider(api_key="test-key")
        assert provider.timeout >= 120  # Should be at least 2 minutes for cold starts

    def test_auth_header_uses_token(self):
        """Test that auth header uses 'Token' prefix (not Bearer)."""
        provider = ReplicateProvider(api_key="r8_my_token")
        assert provider.client.headers["Authorization"] == "Token r8_my_token"


class TestReplicateProviderCapabilities:
    """Tests for ReplicateProvider capability reporting."""

    def test_name_property(self):
        """Test provider name."""
        provider = ReplicateProvider(api_key="test-key")
        assert provider.name == "replicate"

    def test_supports_tools_false(self):
        """Test tool support reporting - Replicate doesn't support tools."""
        provider = ReplicateProvider(api_key="test-key")
        assert provider.supports_tools() is False

    def test_supports_streaming(self):
        """Test streaming support reporting."""
        provider = ReplicateProvider(api_key="test-key")
        assert provider.supports_streaming() is True


class TestReplicateProviderModels:
    """Tests for model definitions."""

    def test_model_definitions_exist(self):
        """Test that model definitions are present."""
        assert len(REPLICATE_MODELS) > 0

    def test_llama_models_defined(self):
        """Test Llama models are defined."""
        assert "meta/llama-3.3-70b-instruct" in REPLICATE_MODELS
        assert "meta/llama-3.1-405b-instruct" in REPLICATE_MODELS

    def test_no_tool_support_in_models(self):
        """Test that no Replicate models support tools."""
        for model_id, model_info in REPLICATE_MODELS.items():
            assert model_info.get("supports_tools") is False, f"{model_id} should not support tools"

    def test_deepseek_model_defined(self):
        """Test DeepSeek V3 is defined."""
        assert "deepseek-ai/deepseek-v3" in REPLICATE_MODELS


class TestReplicateProviderMessageConversion:
    """Tests for message to prompt conversion."""

    def test_messages_to_prompt_basic(self):
        """Test basic message to prompt conversion."""
        provider = ReplicateProvider(api_key="test-key")
        from victor.providers.base import Message

        messages = [Message(role="user", content="Hello, how are you?")]
        prompt = provider._messages_to_prompt(messages)

        assert "<|begin_of_text|>" in prompt
        assert "<|start_header_id|>user<|end_header_id|>" in prompt
        assert "Hello, how are you?" in prompt
        assert "<|start_header_id|>assistant<|end_header_id|>" in prompt  # Starts assistant turn

    def test_messages_to_prompt_with_system(self):
        """Test message conversion with system message."""
        provider = ReplicateProvider(api_key="test-key")
        from victor.providers.base import Message

        messages = [
            Message(role="system", content="You are a helpful assistant"),
            Message(role="user", content="Hi"),
        ]
        prompt = provider._messages_to_prompt(messages)

        assert "<|start_header_id|>system<|end_header_id|>" in prompt
        assert "You are a helpful assistant" in prompt

    def test_messages_to_prompt_conversation(self):
        """Test message conversion with multi-turn conversation."""
        provider = ReplicateProvider(api_key="test-key")
        from victor.providers.base import Message

        messages = [
            Message(role="user", content="What is 2+2?"),
            Message(role="assistant", content="2+2 equals 4."),
            Message(role="user", content="What about 3+3?"),
        ]
        prompt = provider._messages_to_prompt(messages)

        assert "What is 2+2?" in prompt
        assert "2+2 equals 4." in prompt
        assert "What about 3+3?" in prompt


class TestReplicateProviderPrediction:
    """Tests for prediction creation."""

    @pytest.mark.asyncio
    async def test_create_prediction_with_version(self):
        """Test prediction creation with explicit version."""
        provider = ReplicateProvider(api_key="test-key")

        mock_response = MagicMock()
        mock_response.json.return_value = {
            "id": "pred_123",
            "status": "starting",
            "urls": {"get": "https://api.replicate.com/v1/predictions/pred_123"},
        }
        mock_response.raise_for_status = MagicMock()

        with patch.object(provider.client, "post", new_callable=AsyncMock) as mock_post:
            mock_post.return_value = mock_response

            result = await provider._create_prediction(
                model="meta/llama-3.3-70b-instruct:abc123",
                prompt="Hello",
                temperature=0.7,
                max_tokens=100,
            )

            assert result["id"] == "pred_123"
            call_args = mock_post.call_args
            assert call_args[1]["json"]["version"] == "abc123"

    @pytest.mark.asyncio
    async def test_create_prediction_without_version(self):
        """Test prediction creation using latest version."""
        provider = ReplicateProvider(api_key="test-key")

        mock_response = MagicMock()
        mock_response.json.return_value = {
            "id": "pred_456",
            "status": "starting",
        }
        mock_response.raise_for_status = MagicMock()

        with patch.object(provider.client, "post", new_callable=AsyncMock) as mock_post:
            mock_post.return_value = mock_response

            result = await provider._create_prediction(
                model="meta/llama-3.3-70b-instruct",
                prompt="Hello",
                temperature=0.7,
                max_tokens=100,
            )

            assert result["id"] == "pred_456"
            # Should use models endpoint for latest version
            call_args = mock_post.call_args
            url = call_args[0][0]
            assert "/models/meta/llama-3.3-70b-instruct/predictions" in url


class TestReplicateProviderChat:
    """Tests for chat completion."""

    @pytest.mark.asyncio
    async def test_chat_success(self):
        """Test successful chat completion."""
        provider = ReplicateProvider(api_key="test-key")

        # Mock create prediction
        with patch.object(provider, "_create_prediction", new_callable=AsyncMock) as mock_create:
            mock_create.return_value = {"id": "pred_123"}

            # Mock wait for prediction
            with patch.object(
                provider, "_wait_for_prediction", new_callable=AsyncMock
            ) as mock_wait:
                mock_wait.return_value = {
                    "id": "pred_123",
                    "status": "succeeded",
                    "output": ["Hello", "! How", " can I help?"],
                }

                from victor.providers.base import Message

                result = await provider.chat(
                    messages=[Message(role="user", content="Hello")],
                    model="meta/llama-3.3-70b-instruct",
                )

                assert result.content == "Hello! How can I help?"
                assert result.role == "assistant"

    @pytest.mark.asyncio
    async def test_chat_string_output(self):
        """Test chat with string output (not list)."""
        provider = ReplicateProvider(api_key="test-key")

        with patch.object(provider, "_create_prediction", new_callable=AsyncMock) as mock_create:
            mock_create.return_value = {"id": "pred_123"}

            with patch.object(
                provider, "_wait_for_prediction", new_callable=AsyncMock
            ) as mock_wait:
                mock_wait.return_value = {
                    "status": "succeeded",
                    "output": "Direct string output",
                }

                from victor.providers.base import Message

                result = await provider.chat(
                    messages=[Message(role="user", content="Hello")],
                    model="meta/llama-3.3-70b-instruct",
                )

                assert result.content == "Direct string output"

    @pytest.mark.asyncio
    async def test_chat_prediction_failed(self):
        """Test handling of failed prediction."""
        provider = ReplicateProvider(api_key="test-key")

        with patch.object(provider, "_create_prediction", new_callable=AsyncMock) as mock_create:
            mock_create.return_value = {"id": "pred_123"}

            with patch.object(
                provider, "_wait_for_prediction", new_callable=AsyncMock
            ) as mock_wait:
                mock_wait.return_value = {
                    "status": "failed",
                    "error": "Model crashed",
                }

                from victor.providers.base import Message, ProviderError

                with pytest.raises(ProviderError) as exc_info:
                    await provider.chat(
                        messages=[Message(role="user", content="Hello")],
                        model="meta/llama-3.3-70b-instruct",
                    )

                assert "failed" in str(exc_info.value).lower()

    @pytest.mark.asyncio
    async def test_chat_timeout(self):
        """Test chat timeout handling."""
        provider = ReplicateProvider(api_key="test-key")

        with patch.object(provider, "_create_prediction", new_callable=AsyncMock) as mock_create:
            mock_create.side_effect = httpx.TimeoutException("Timeout")

            from victor.providers.base import Message, ProviderTimeoutError

            with pytest.raises(ProviderTimeoutError):
                await provider.chat(
                    messages=[Message(role="user", content="Hello")],
                    model="meta/llama-3.3-70b-instruct",
                )


class TestReplicateProviderWaitForPrediction:
    """Tests for prediction polling."""

    @pytest.mark.asyncio
    async def test_wait_for_prediction_immediate_success(self):
        """Test immediate prediction success."""
        provider = ReplicateProvider(api_key="test-key")

        mock_response = MagicMock()
        mock_response.json.return_value = {
            "id": "pred_123",
            "status": "succeeded",
            "output": "Result",
        }
        mock_response.raise_for_status = MagicMock()

        with patch.object(provider.client, "get", new_callable=AsyncMock) as mock_get:
            mock_get.return_value = mock_response

            result = await provider._wait_for_prediction("pred_123")

            assert result["status"] == "succeeded"
            assert result["output"] == "Result"

    @pytest.mark.asyncio
    async def test_wait_for_prediction_polls(self):
        """Test prediction polling until completion."""
        provider = ReplicateProvider(api_key="test-key")

        responses = [
            {"id": "pred_123", "status": "starting"},
            {"id": "pred_123", "status": "processing"},
            {"id": "pred_123", "status": "succeeded", "output": "Done!"},
        ]

        mock_response = MagicMock()
        mock_response.raise_for_status = MagicMock()

        call_count = 0

        def side_effect(*args, **kwargs):
            nonlocal call_count
            mock_response.json.return_value = responses[min(call_count, len(responses) - 1)]
            call_count += 1
            return mock_response

        with patch.object(provider.client, "get", new_callable=AsyncMock) as mock_get:
            mock_get.side_effect = side_effect

            with patch("asyncio.sleep", new_callable=AsyncMock):
                result = await provider._wait_for_prediction("pred_123")

                assert result["status"] == "succeeded"
                assert call_count == 3


class TestReplicateProviderStreaming:
    """Tests for streaming functionality."""

    @pytest.mark.asyncio
    async def test_stream_fallback_to_polling(self):
        """Test streaming falls back to polling when no stream URL."""
        provider = ReplicateProvider(api_key="test-key")

        with patch.object(provider, "_create_prediction", new_callable=AsyncMock) as mock_create:
            # No stream URL in response
            mock_create.return_value = {"id": "pred_123", "urls": {"get": "..."}}

            with patch.object(
                provider, "_wait_for_prediction", new_callable=AsyncMock
            ) as mock_wait:
                mock_wait.return_value = {
                    "status": "succeeded",
                    "output": ["Hello there!"],
                }

                from victor.providers.base import Message

                chunks = []
                async for chunk in provider.stream(
                    messages=[Message(role="user", content="Hi")],
                    model="meta/llama-3.3-70b-instruct",
                ):
                    chunks.append(chunk)

                assert len(chunks) == 1
                assert chunks[0].content == "Hello there!"
                assert chunks[0].is_final is True


class TestReplicateProviderCleanup:
    """Tests for resource cleanup."""

    @pytest.mark.asyncio
    async def test_close(self):
        """Test provider cleanup."""
        provider = ReplicateProvider(api_key="test-key")

        with patch.object(provider.client, "aclose", new_callable=AsyncMock) as mock_close:
            await provider.close()
            mock_close.assert_called_once()
