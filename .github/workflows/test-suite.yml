name: Comprehensive Test Suite

on:
  push:
    branches: [main, develop, 'release/**', 'feature/**']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - smoke
          - performance
      python_version:
        description: 'Python version to test'
        required: false
        default: '3.11'
        type: choice
        options:
          - '3.10'
          - '3.11'
          - '3.12'

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  # Use CPU-only torch for faster CI (saves ~800MB download)
  PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
  # Disable telemetry
  VICTOR_TELEMETRY_ENABLED: false
  # Enable test mode
  VICTOR_TEST_MODE: true
  # Skip .env file loading in tests
  VICTOR_SKIP_ENV_FILE: 1

jobs:
  # =============================================================================
  # Job 1: Unit Tests - Fast, isolated tests
  # =============================================================================
  unit-tests:
    name: Unit Tests (Python ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
        os: [ubuntu-latest]
        include:
          - python-version: '3.11'
            os: macos-latest
          - python-version: '3.11'
            os: windows-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip

      - name: Install system dependencies (Ubuntu)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential curl git

      - name: Install system dependencies (macOS)
        if: runner.os == 'macOS'
        run: |
          brew install libgit2

      - name: Install dependencies
        shell: bash
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          # Install torch with CPU-only support
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          # Install dev dependencies
          pip install -e ".[dev]"

      - name: Run unit tests with coverage
        shell: bash
        run: |
          pytest tests/unit -v \
            --timeout=60 \
            --cov=victor \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing:skip-covered \
            --cov-context=test \
            --cov-fail-under=50 \
            --tb=short \
            --maxfail=10 \
            -m "not slow" \
            --color=yes

      - name: Generate coverage summary
        if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
        run: |
          echo "# Unit Tests Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          coverage report >> $GITHUB_STEP_SUMMARY || true

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Top 20 Best Covered Modules" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          coverage report --sort=cover | head -25 >> $GITHUB_STEP_SUMMARY || true

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Coverage by Component" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Agent Components" >> $GITHUB_STEP_SUMMARY
          coverage report --include='victor/agent/*' --sort=cover >> $GITHUB_STEP_SUMMARY || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Framework Components" >> $GITHUB_STEP_SUMMARY
          coverage report --include='victor/framework/*' --sort=cover >> $GITHUB_STEP_SUMMARY || true
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Provider Components" >> $GITHUB_STEP_SUMMARY
          coverage report --include='victor/providers/*' --sort=cover >> $GITHUB_STEP_SUMMARY || true

      - name: Upload coverage to Codecov
        if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false
          flags: unit-tests
          name: codecov-unit-tests-${{ matrix.os }}
          token: ${{ secrets.CODECOV_TOKEN }}

      - name: Upload coverage HTML
        if: matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-unit-tests-${{ matrix.os }}
          path: htmlcov/
          retention-days: 7

  # =============================================================================
  # Job 2: Integration Tests - Tests requiring external services
  # =============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential curl git

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          pip install -e ".[dev]"

      - name: Run integration tests
        run: |
          # Use shorter timeout in CI, timeouts are skipped instead of failed
          pytest tests/integration -v \
            --timeout=60 \
            --cov=victor \
            --cov-report=xml \
            --cov-report=term-missing:skip-covered \
            --cov-append \
            --tb=short \
            --maxfail=5 \
            -m "not slow" \
            --color=yes

      - name: Generate coverage summary
        run: |
          echo "# Integration Tests Coverage Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          coverage report >> $GITHUB_STEP_SUMMARY || true

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          fail_ci_if_error: false
          flags: integration-tests
          name: codecov-integration-tests
          token: ${{ secrets.CODECOV_TOKEN }}

  # =============================================================================
  # Job 3: Smoke Tests - Quick sanity checks
  # =============================================================================
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          pip install -e ".[dev]"

      - name: Run smoke tests
        run: |
          pytest tests/smoke -v \
            --tb=short \
            --maxfail=3 \
            --color=yes

      - name: CLI smoke test
        run: |
          victor --help
          victor version || echo "Version command not available"

  # NOTE: Framework Tests and Coordinator Tests were removed as they're redundant
  # - Framework tests (tests/unit/framework) are already covered by unit-tests
  # - Coordinator tests (tests/unit/agent/test_coordinators.py) are already covered by unit-tests
  # This reduces CI time and avoids duplicate test runs.

  # =============================================================================
  # Job 4: Performance Tests - Benchmark performance
  # =============================================================================
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          pip install -e ".[dev]"

      - name: Run performance benchmarks
        run: |
          pytest tests/benchmark/test_performance_baselines.py -v \
            --benchmark-only \
            --benchmark-json=benchmark-results.json \
            --tb=short \
            -m benchmark \
            --color=yes

      - name: Generate performance summary
        run: |
          echo "# Performance Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          python -c "
          import json
          import sys
          try:
              with open('benchmark-results.json', 'r') as f:
                  data = json.load(f)
                  print('## Benchmarks')
                  print('')
                  for bench in data.get('benchmarks', []):
                      name = bench.get('name', 'unknown')
                      stats = bench.get('stats', {})
                      mean = stats.get('mean', 0)
                      print(f'- **{name}**: {mean:.4f}s')
          except Exception as e:
              print(f'Error reading benchmark results: {e}', file=sys.stderr)
          " >> $GITHUB_STEP_SUMMARY || true

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: benchmark-results.json
          retention-days: 30

  # =============================================================================
  # Job 7: Test Report - Aggregate and report results
  # =============================================================================
  test-report:
    name: Test Summary Report
    runs-on: ubuntu-latest
    if: always()
    needs: [unit-tests, integration-tests, smoke-tests, performance-tests]

    steps:
      - name: Download all artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Generate comprehensive test summary
        run: |
          cat > test-summary.md << 'EOF'
          # Comprehensive Test Suite Summary

          **Workflow**: ${{ github.workflow }}
          **Run ID**: ${{ github.run_id }}
          **Branch**: ${{ github.ref_name }}
          **Commit**: ${{ github.sha }}
          **Triggered by**: ${{ github.event_name }}

          ## Test Results Overview

          | Test Suite | Status | Details |
          |-------------|--------|---------|
          | Unit Tests | ${{ needs.unit-tests.result }} | Python 3.10, 3.11, 3.12 on Ubuntu, macOS, Windows |
          | Integration Tests | ${{ needs.integration-tests.result }} | Full integration test suite |
          | Smoke Tests | ${{ needs.smoke-tests.result }} | Quick sanity checks |
          | Performance Tests | ${{ needs.performance-tests.result }} | Performance benchmarks |

          ## Overall Status

          EOF

          # Add overall status
          if [ "${{ needs.unit-tests.result }}" == "success" ] && \
             [ "${{ needs.integration-tests.result }}" == "success" ] && \
             [ "${{ needs.smoke-tests.result }}" == "success" ]; then
            echo "✅ **All test suites passed!**" >> test-summary.md
          else
            echo "❌ **Some test suites failed. Please review the logs above.**" >> test-summary.md
          fi

          cat >> test-summary.md << 'EOF'

          ## Coverage Reports

          Coverage reports have been uploaded to Codecov for each test suite.
          - Unit Tests: `unit-tests` flag
          - Integration Tests: `integration-tests` flag

          ## Artifacts

          - Coverage HTML reports: Available in the workflow artifacts
          - Benchmark results: `benchmark-results.json`
          - Test logs: Available in the workflow run logs

          ## Quick Links

          - [Codecov Dashboard](https://codecov.io/gh/${{ github.repository }})
          - [Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          - [Test Summary](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}/attempts/)

          ---

          _This report was automatically generated by the Comprehensive Test Suite workflow_
          EOF

          cat test-summary.md

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary-report
          path: test-summary.md
          retention-days: 30

      - name: Add to job summary
        run: cat test-summary.md >> $GITHUB_STEP_SUMMARY

      - name: Check overall status
        run: |
          if [ "${{ needs.unit-tests.result }}" != "success" ] || \
             [ "${{ needs.integration-tests.result }}" != "success" ] || \
             [ "${{ needs.smoke-tests.result }}" != "success" ]; then
            echo "::error::One or more test suites failed. Please review the logs."
            exit 1
          fi
