name: Comprehensive Test Regression (100% TDD)

on:
  push:
    branches: [main, develop, 'release/**', 'feature/**']
  pull_request:
    branches: [main, develop]
  workflow_dispatch:
    inputs:
      test_category:
        description: 'Test category to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - unit
          - integration
          - smoke
          - performance
          - load
          - security
          - deployment
          - property

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  # Use CPU-only torch for faster CI
  PIP_EXTRA_INDEX_URL: https://download.pytorch.org/whl/cpu
  # Disable telemetry
  VICTOR_TELEMETRY_ENABLED: false
  # Enable test mode
  VICTOR_TEST_MODE: true
  # Skip .env file loading in tests
  VICTOR_SKIP_ENV_FILE: 1

jobs:
  # =============================================================================
  # Category 1: Unit Tests - Fast, isolated tests
  # =============================================================================
  unit-tests:
    name: Unit Tests
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.10', '3.11', '3.12']
        os: [ubuntu-latest]
        include:
          - python-version: '3.11'
            os: macos-latest

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip

      - name: Install system dependencies
        run: |
          if [[ "$RUNNER_OS" == "Linux" ]]; then
            sudo apt-get update
            sudo apt-get install -y build-essential curl git
          elif [[ "$RUNNER_OS" == "macOS" ]]; then
            # macOS already has build-essential tools via Xcode Command Line Tools
            brew install curl git || true
          fi
        shell: bash

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          pip install -e ".[dev]"

      - name: Run unit tests
        run: |
          pytest tests/unit -v \
            --timeout=60 \
            --tb=short \
            --maxfail=10 \
            -m "not slow" \
            --color=yes

  # =============================================================================
  # Category 2: Integration Tests - Cross-component tests
  # =============================================================================
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install "pip>=25.2"
          pip install torch --index-url https://download.pytorch.org/whl/cpu || pip install torch
          pip install -e ".[dev]"

      - name: Run integration tests
        run: |
          pytest tests/integration -v \
            --timeout=300 \
            --tb=short \
            --maxfail=5 \
            --color=yes

  # =============================================================================
  # Category 3: Property-Based Tests - Hypothesis/QuickCheck style
  # =============================================================================
  property-tests:
    name: Property-Based Tests
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run property-based tests
        run: |
          pytest tests/property -v \
            --timeout=120 \
            --tb=short \
            --color=yes

  # =============================================================================
  # Category 4: Security Tests - Authorization, penetration, audit
  # =============================================================================
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run security tests
        run: |
          pytest tests/security -v \
            --timeout=120 \
            --tb=short \
            --color=yes

  # =============================================================================
  # Category 5: Deployment Tests - Environment deployment validation
  # =============================================================================
  deployment-tests:
    name: Deployment Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run deployment tests
        run: |
          pytest tests/deployment -v \
            --timeout=180 \
            --tb=short \
            --color=yes

  # =============================================================================
  # Category 6: Performance Tests - Benchmark validation
  # =============================================================================
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run performance tests
        run: |
          pytest tests/performance tests/benchmark -v \
            --timeout=300 \
            --tb=short \
            --maxfail=3 \
            --color=yes

  # =============================================================================
  # Category 7: Load Tests - Stress and scalability tests (manual trigger only)
  # =============================================================================
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.test_category == 'load'

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Start API server in background
        run: |
          victor serve --host 0.0.0.0 --port 8765 &
          echo $! > server.pid
          # Wait for server to be ready
          for i in {1..30}; do
            if curl -s http://localhost:8765/health > /dev/null 2>&1; then
              echo "Server is ready"
              break
            fi
            echo "Waiting for server... ($i/30)"
            sleep 2
          done

      - name: Run Locust load tests
        run: |
          if [ -d "tests/load/locustfiles" ]; then
            for locustfile in tests/load/locustfiles/*.py; do
              echo "Running locust tests from $locustfile"
              locust -f "$locustfile" \
                --headless \
                --users 50 \
                --spawn-rate 5 \
                --run-time 60s \
                --host http://localhost:8765 \
                --html locust_report.html
            done
          fi

      - name: Upload Locust reports
        uses: actions/upload-artifact@v4
        with:
          name: locust-reports
          path: locust_report.html
          retention-days: 30

      - name: Stop API server
        if: always()
        run: |
          if [ -f server.pid ]; then
            kill $(cat server.pid) || true
            rm server.pid
          fi

  # =============================================================================
  # Category 8: Smoke Tests - Quick validation
  # =============================================================================
  smoke-tests:
    name: Smoke Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run smoke tests
        run: |
          pytest tests/smoke -v \
            --timeout=60 \
            --tb=short \
            --color=yes

  # =============================================================================
  # Category 9: QA Tests - Comprehensive quality assurance
  # =============================================================================
  qa-tests:
    name: QA Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[dev]"

      - name: Run QA tests
        run: |
          pytest tests/qa -v \
            --timeout=300 \
            --tb=short \
            --color=yes

  # =============================================================================
  # Summary: Aggregate all test results
  # =============================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, property-tests, security-tests, deployment-tests, performance-tests, smoke-tests, qa-tests]
    if: always()

    steps:
      - name: Check test results
        run: |
          echo "# Test Regression Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Categories Executed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "✅ Unit Tests - Fast, isolated tests" >> $GITHUB_STEP_SUMMARY
          echo "✅ Integration Tests - Cross-component tests" >> $GITHUB_STEP_SUMMARY
          echo "✅ Property-Based Tests - Hypothesis/QuickCheck style" >> $GITHUB_STEP_SUMMARY
          echo "✅ Security Tests - Authorization, penetration, audit" >> $GITHUB_STEP_SUMMARY
          echo "✅ Deployment Tests - Environment deployment validation" >> $GITHUB_STEP_SUMMARY
          echo "✅ Performance Tests - Benchmark validation" >> $GITHUB_STEP_SUMMARY
          echo "⚠️  Load Tests - Manual trigger only (use workflow_dispatch)" >> $GITHUB_STEP_SUMMARY
          echo "✅ Smoke Tests - Quick validation" >> $GITHUB_STEP_SUMMARY
          echo "✅ QA Tests - Comprehensive quality assurance" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Coverage" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Directories Covered:** 8/8 automated + 1 manual (100%)" >> $GITHUB_STEP_SUMMARY
          echo "- **TDD Regression Gate:** ✅ PASSED" >> $GITHUB_STEP_SUMMARY

      - name: Verify all jobs passed
        run: |
          if [ "${{ needs.unit-tests.result }}" != "success" ] || \
             [ "${{ needs.integration-tests.result }}" != "success" ] || \
             [ "${{ needs.property-tests.result }}" != "success" ] || \
             [ "${{ needs.security-tests.result }}" != "success" ] || \
             [ "${{ needs.deployment-tests.result }}" != "success" ] || \
             [ "${{ needs.performance-tests.result }}" != "success" ] || \
             [ "${{ needs.smoke-tests.result }}" != "success" ] || \
             [ "${{ needs.qa-tests.result }}" != "success" ]; then
            echo "❌ Some test categories failed. See above for details."
            exit 1
          fi
          echo "✅ All test categories passed!"
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Load Tests" >> $GITHUB_STEP_SUMMARY
          echo "Load tests require manual triggering via workflow_dispatch." >> $GITHUB_STEP_SUMMARY
          echo "This prevents unnecessary CI runs and resource usage." >> $GITHUB_STEP_SUMMARY
