# Victor Production Environment Configuration
# ============================================================
# ðŸš¨ REQUIRED: Fill in the sections marked with TODO below
# ============================================================

# ============================================================
# API Keys (Required for cloud providers)
# ============================================================
# TODO: Add at least ONE API key below (uncomment and add your key)
# You can also use air-gapped mode with Ollama (see bottom of file)

# Anthropic (Claude) - Recommended for best performance
# TODO: Uncomment and add your Anthropic API key
# ANTHROPIC_API_KEY=sk-ant-your-key-here

# OpenAI (GPT-4, GPT-3.5)
# TODO: Uncomment and add your OpenAI API key if using
# OPENAI_API_KEY=sk-your-key-here

# Google (Gemini)
# TODO: Uncomment and add your Google API key if using
# GOOGLE_API_KEY=your-google-api-key

# Optional providers (uncomment if needed)
# XAI_API_KEY=your-xai-key  # For Grok
# GROQ_API_KEY=your-groq-key  # For Groq inference

# ============================================================
# Victor Configuration
# ============================================================

VICTOR_ENV=production
VICTOR_LOG_LEVEL=INFO
VICTOR_GRAPH_STORE=sqlite
VICTOR_ENABLE_OBSERVABILITY=true
VICTOR_ENABLE_PROMETHEUS_EXPORT=true

# ============================================================
# Local LLM Configuration (Optional)
# ============================================================

# Ollama (detected running on port 11434)
OLLAMA_HOST=http://host.docker.internal:11434
OLLAMA_PORT=11434

# vLLM (if using)
# VLLM_API_BASE=http://vllm:8000/v1

# LMStudio (if using)
# LMSTUDIO_BASE_URL=http://host.docker.internal:1234

# ============================================================
# Service Ports
# ============================================================

VICTOR_API_PORT=8765
VICTOR_METRICS_PORT=9090
PROMETHEUS_PORT=9091
GRAFANA_PORT=3000
ALERTMANAGER_PORT=9093

# ============================================================
# Monitoring Configuration
# ============================================================

# Grafana admin credentials
# Default password for initial deployment - change after first login
GRAFANA_ADMIN_USER=admin
GRAFANA_ADMIN_PASSWORD=victor_admin_2025

# ============================================================
# Performance Tuning
# ============================================================

VICTOR_MAX_CONCURRENT_TOOLS=5
VICTOR_ENABLE_PARALLEL_EXECUTION=true
VICTOR_TOOL_CACHE_TTL=300

# ============================================================
# Storage Configuration
# ============================================================

VICTOR_CACHE_DIR=/home/victor/.victor/cache
VICTOR_GRAPH_PATH=/home/victor/.victor/graph/graph.db

# ============================================================
# Security (Production)
# ============================================================

# Set to true for air-gapped deployment (local LLMs only, no external API calls)
# Note: Ollama is already running on your system (port 11434)
# Configured for air-gapped mode deployment with Ollama
VICTOR_AIRGAPPED_MODE=true

# Enable/disable features
VICTOR_ENABLE_WEB_SEARCH=true
VICTOR_ENABLE_WEB_FETCH=true

# ============================================================
# DEPLOYMENT CHECKLIST
# ============================================================
# Before running ./scripts/deploy-production.sh:
#
# âœ… Step 1: Add at least ONE API key above (or enable air-gapped mode)
# âœ… Step 2: Change GRAFANA_ADMIN_PASSWORD to a strong password
# âœ… Step 3: Review and customize other settings if needed
# âœ… Step 4: Save this file
# âœ… Step 5: Run: ./scripts/deploy-production.sh
#
# For air-gapped mode (Ollama only, no cloud APIs):
#   1. Set VICTOR_AIRGAPPED_MODE=true
#   2. No API keys needed
#   3. Ollama must be running (it is - port 11434 detected)
# ============================================================
