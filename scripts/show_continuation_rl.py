#!/usr/bin/env python3
"""Show continuation prompt RL learning status and recommendations.

This script displays:
1. Current RL learning statistics for all provider:model combinations
2. Recommended continuation prompt adjustments
3. Recent outcomes history
4. Suggestions for manual configuration

Usage:
    python scripts/show_continuation_rl.py
    python scripts/show_continuation_rl.py --export profiles.yaml
    python scripts/show_continuation_rl.py --provider ollama --model qwen3-coder-tools:30b-128k
"""

import argparse
import sys
from pathlib import Path

# Add project root to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from victor.agent.rl.coordinator import get_rl_coordinator
import sqlite3


def main():
    parser = argparse.ArgumentParser(description="Show continuation prompt RL learning status")
    parser.add_argument("--provider", help="Filter by provider name (e.g., 'ollama', 'anthropic')")
    parser.add_argument("--model", help="Filter by model name (e.g., 'qwen3-coder-tools:30b-128k')")
    parser.add_argument(
        "--export",
        metavar="FILE",
        help="Export recommendations to YAML file for profiles.yaml",
    )
    args = parser.parse_args()

    # Get coordinator and learner
    coordinator = get_rl_coordinator()
    learner = coordinator.get_learner("continuation_prompts")
    if not learner:
        print("Continuation prompts learner not available")
        return

    # Query database for stats
    conn = sqlite3.connect(str(coordinator.db_path))
    cursor = conn.cursor()

    cursor.execute(
        """
        SELECT context_key, provider, model, task_type, total_sessions,
               successful_sessions, stuck_loop_count, forced_completion_count,
               avg_quality_score, avg_prompts_used, current_max_prompts,
               recommended_max_prompts
        FROM continuation_prompts_stats
        ORDER BY total_sessions DESC
    """
    )

    print("=" * 80)
    print("CONTINUATION PROMPT RL LEARNING STATUS")
    print("=" * 80)
    print()

    rows = cursor.fetchall()
    if not rows:
        print("No continuation prompt learning data found yet.")
        conn.close()
        return

    for row in rows:
        (
            context_key,
            provider,
            model,
            task_type,
            total,
            successful,
            stuck,
            forced,
            avg_quality,
            avg_prompts,
            current_max,
            recommended,
        ) = row

        # Apply filters if provided
        if args.provider and provider != args.provider:
            continue
        if args.model and model != args.model:
            continue

        success_rate = (successful / total * 100) if total > 0 else 0
        stuck_rate = (stuck / total * 100) if total > 0 else 0

        print(f"{provider}:{model} - {task_type}")
        print(f"  Sessions: {total} ({successful} successful)")
        print(f"  Success Rate: {success_rate:.1f}%")
        print(f"  Avg Quality: {avg_quality:.2f}")
        print(f"  Stuck Rate: {stuck_rate:.1f}% ({stuck} stuck loops)")
        print(f"  Forced Completions: {forced}")
        print(f"  Avg Prompts Used: {avg_prompts:.1f}")
        print(f"  Current Max: {current_max}")
        if recommended is not None:
            change = recommended - current_max
            print(f"  ✨ Recommended: {recommended} ({change:+d})")
        print()

    # Export recommendations if requested
    if args.export:
        # Query for recommendations from database
        cursor.execute(
            """
            SELECT provider, model, task_type, recommended_max_prompts
            FROM continuation_prompts_stats
            WHERE recommended_max_prompts IS NOT NULL
        """
        )

        recommendations = {}
        for provider, model, task_type, recommended in cursor.fetchall():
            key = f"{provider}:{model}:{task_type}"
            recommendations[key] = recommended

        conn.close()

        if not recommendations:
            print("\nNo recommendations to export yet (need more data)")
            return

        import yaml

        output = {
            "continuation_prompt_overrides": recommendations,
            "enable_continuation_rl_learning": True,
        }

        filepath = Path(args.export)
        with open(filepath, "w") as f:
            f.write("# Auto-generated continuation prompt recommendations\n")
            f.write("# Generated by: python scripts/show_continuation_rl.py --export\n")
            f.write("# Based on SQLite database continuation_prompts_stats table\n\n")
            yaml.dump(output, f, default_flow_style=False, sort_keys=False)

        print(f"\n✅ Exported recommendations to: {filepath}")
        print(f"   Provider:Model:TaskType combinations: {len(recommendations)}")
        print("\nTo use these recommendations:")
        print(f"1. Merge {filepath} into your ~/.victor/profiles.yaml")
        print("2. Or copy the continuation_prompt_overrides section manually")
    else:
        conn.close()


if __name__ == "__main__":
    main()
